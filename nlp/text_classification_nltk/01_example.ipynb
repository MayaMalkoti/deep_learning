{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Movie review classification with NLTK </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cats = movie_reviews.categories()\n",
    "reviews = []\n",
    "for cat in cats:\n",
    "    for fid in movie_reviews.fileids(cat):\n",
    "        review = (list(movie_reviews.words(fid)),cat)\n",
    "        reviews.append(review)\n",
    "random.shuffle(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_wd_in_reviews = nltk.FreqDist(wd.lower() for wd in movie_reviews.words())\n",
    "top_wd_in_reviews = [list(wds) for wds in zip(*all_wd_in_reviews.most_common(2000))][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ext_ft(review,top_words):\n",
    "    review_wds = set(review)\n",
    "    ft = {}\n",
    "    for wd in top_words:\n",
    "        ft['word_present({})'.format(wd)] = (wd in review_wds)\n",
    "    return ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresets = [(ext_ft(d,top_wd_in_reviews), c) for (d,c) in reviews]\n",
    "train_set, test_set = featuresets[200:], featuresets[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "    word_present(seagal) = True              neg : pos    =     12.9 : 1.0\n",
      "word_present(outstanding) = True              pos : neg    =     10.2 : 1.0\n",
      "     word_present(mulan) = True              pos : neg    =      7.0 : 1.0\n",
      "word_present(wonderfully) = True              pos : neg    =      6.5 : 1.0\n",
      "     word_present(damon) = True              pos : neg    =      5.7 : 1.0\n",
      "word_present(ridiculous) = True              neg : pos    =      5.6 : 1.0\n",
      "     word_present(awful) = True              neg : pos    =      5.6 : 1.0\n",
      "      word_present(lame) = True              neg : pos    =      5.5 : 1.0\n",
      "       word_present(era) = True              pos : neg    =      5.4 : 1.0\n",
      "     word_present(waste) = True              neg : pos    =      5.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_vect=None\n",
    "def get_train_test(tr_set,te_set):\n",
    "    global d_vect\n",
    "    d_vect = DictVectorizer(sparse=False)\n",
    "    X_tr, y_tr = zip(*tr_set)\n",
    "    X_tr = d_vect.fit_transform(X_tr)\n",
    "    X_te,y_te = zip(*te_set)\n",
    "    X_te = d_vect.transform(X_te)\n",
    "    return X_tr,X_te,y_tr,y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=4,\n",
       "            oob_score=False, random_state=10, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = get_train_test(train_set,test_set)\n",
    "rf = RandomForestClassifier(n_estimators=100,n_jobs=4,random_state=10)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.825\n"
     ]
    }
   ],
   "source": [
    "preds = rf.predict(X_test)\n",
    "print(accuracy_score(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords_list = stopwords.words('english')\n",
    "all_words_in_reviews = nltk.FreqDist(word.lower() for word in movie_reviews.words() if word not in stopwords_list)\n",
    "top_words_in_reviews = [list(words) for words in zip(*all_words_in_reviews.most_common(2000))][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featuresets = [(ext_ft(d,top_words_in_reviews), c) for (d,c) in reviews]\n",
    "train_set, test_set = featuresets[200:], featuresets[:200]\n",
    "X_train,X_test,y_train,y_test = get_train_test(train_set,test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=4,\n",
       "            oob_score=False, random_state=10, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100,n_jobs=4,random_state=10)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.855\n"
     ]
    }
   ],
   "source": [
    "preds = rf.predict(X_test)\n",
    "print(accuracy_score(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('word_present(bad)', 0.012709101728574842), ('word_present(worst)', 0.007818498310639065), ('word_present(boring)', 0.005936688132114715), ('word_present(stupid)', 0.005494943898958303), ('word_present(waste)', 0.005091693110187572), ('word_present(awful)', 0.004958501019474184), ('word_present(life)', 0.004823972835890037), ('word_present(mess)', 0.004702269754432544), ('word_present(plot)', 0.004651200149051172), ('word_present(ridiculous)', 0.004302553379352463), ('word_present(lame)', 0.004211512878104104), ('word_present(wasted)', 0.003801230103927904), ('word_present(perfectly)', 0.003652949879118064), ('word_present(supposed)', 0.0036088721850700816), ('word_present(excellent)', 0.0034587221482947376), ('word_present(script)', 0.0033971166771779187), ('word_present(dull)', 0.0033936795346628922), ('word_present(great)', 0.0031970652208558547), ('word_present(?)', 0.0031860349055431846), ('word_present(outstanding)', 0.003175814254058592)]\n"
     ]
    }
   ],
   "source": [
    "features_list = zip(d_vect.get_feature_names(),rf.feature_importances_)\n",
    "features_list = sorted(features_list, key=lambda x: x[1], reverse=True)\n",
    "print(features_list[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
