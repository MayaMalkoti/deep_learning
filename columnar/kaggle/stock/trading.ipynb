{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-08</td>\n",
       "      <td>15.07</td>\n",
       "      <td>15.12</td>\n",
       "      <td>14.63</td>\n",
       "      <td>14.75</td>\n",
       "      <td>8407500</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-11</td>\n",
       "      <td>14.89</td>\n",
       "      <td>15.01</td>\n",
       "      <td>14.26</td>\n",
       "      <td>14.46</td>\n",
       "      <td>8882000</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-02-12</td>\n",
       "      <td>14.45</td>\n",
       "      <td>14.51</td>\n",
       "      <td>14.10</td>\n",
       "      <td>14.27</td>\n",
       "      <td>8126000</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-02-13</td>\n",
       "      <td>14.30</td>\n",
       "      <td>14.94</td>\n",
       "      <td>14.25</td>\n",
       "      <td>14.66</td>\n",
       "      <td>10259500</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-02-14</td>\n",
       "      <td>14.94</td>\n",
       "      <td>14.96</td>\n",
       "      <td>13.16</td>\n",
       "      <td>13.99</td>\n",
       "      <td>31879900</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   open   high    low  close    volume Name\n",
       "0  2013-02-08  15.07  15.12  14.63  14.75   8407500  AAL\n",
       "1  2013-02-11  14.89  15.01  14.26  14.46   8882000  AAL\n",
       "2  2013-02-12  14.45  14.51  14.10  14.27   8126000  AAL\n",
       "3  2013-02-13  14.30  14.94  14.25  14.66  10259500  AAL\n",
       "4  2013-02-14  14.94  14.96  13.16  13.99  31879900  AAL"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('all_stocks_5yr.csv').fillna(0)\n",
    "# df = df.iloc[:5000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = 0\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    \n",
    "    today_close = df.iloc[idx]['close']\n",
    "    try:\n",
    "        tomorrow_high = df.iloc[idx+1]['high'] \n",
    "    except IndexError:\n",
    "        break\n",
    "    if (0.99*tomorrow_high) <= today_close:\n",
    "        df.iat[idx, 7] = 0\n",
    "    else:\n",
    "        df.iat[idx, 7] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year_encoded'] = LabelEncoder().fit_transform(df['year'])\n",
    "df['month_encoded'] = LabelEncoder().fit_transform(df['month'])\n",
    "df['day_encoded'] = LabelEncoder().fit_transform(df['day'])\n",
    "df['name_encoded'] = LabelEncoder().fit_transform(df['Name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['volume_scaled'] = StandardScaler().fit_transform(df[['volume']])\n",
    "df['open_scaled'] = StandardScaler().fit_transform(df[['open']])\n",
    "df['high_scaled'] = StandardScaler().fit_transform(df[['high']])\n",
    "df['low_scaled'] = StandardScaler().fit_transform(df[['low']])\n",
    "df['close_scaled'] = StandardScaler().fit_transform(df[['close']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Name</th>\n",
       "      <th>target</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year_encoded</th>\n",
       "      <th>month_encoded</th>\n",
       "      <th>day_encoded</th>\n",
       "      <th>name_encoded</th>\n",
       "      <th>volume_scaled</th>\n",
       "      <th>open_scaled</th>\n",
       "      <th>high_scaled</th>\n",
       "      <th>low_scaled</th>\n",
       "      <th>close_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-08</td>\n",
       "      <td>15.07</td>\n",
       "      <td>15.12</td>\n",
       "      <td>14.63</td>\n",
       "      <td>14.75</td>\n",
       "      <td>8407500</td>\n",
       "      <td>AAL</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.469964</td>\n",
       "      <td>-0.697812</td>\n",
       "      <td>-0.699105</td>\n",
       "      <td>-0.700725</td>\n",
       "      <td>-0.701242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-11</td>\n",
       "      <td>14.89</td>\n",
       "      <td>15.01</td>\n",
       "      <td>14.26</td>\n",
       "      <td>14.46</td>\n",
       "      <td>8882000</td>\n",
       "      <td>AAL</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524544</td>\n",
       "      <td>-0.699661</td>\n",
       "      <td>-0.700225</td>\n",
       "      <td>-0.704559</td>\n",
       "      <td>-0.704220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-02-12</td>\n",
       "      <td>14.45</td>\n",
       "      <td>14.51</td>\n",
       "      <td>14.10</td>\n",
       "      <td>14.27</td>\n",
       "      <td>8126000</td>\n",
       "      <td>AAL</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.437583</td>\n",
       "      <td>-0.704179</td>\n",
       "      <td>-0.705317</td>\n",
       "      <td>-0.706217</td>\n",
       "      <td>-0.706171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-02-13</td>\n",
       "      <td>14.30</td>\n",
       "      <td>14.94</td>\n",
       "      <td>14.25</td>\n",
       "      <td>14.66</td>\n",
       "      <td>10259500</td>\n",
       "      <td>AAL</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.682994</td>\n",
       "      <td>-0.705719</td>\n",
       "      <td>-0.700938</td>\n",
       "      <td>-0.704663</td>\n",
       "      <td>-0.702166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-02-14</td>\n",
       "      <td>14.94</td>\n",
       "      <td>14.96</td>\n",
       "      <td>13.16</td>\n",
       "      <td>13.99</td>\n",
       "      <td>31879900</td>\n",
       "      <td>AAL</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3.169926</td>\n",
       "      <td>-0.699147</td>\n",
       "      <td>-0.700735</td>\n",
       "      <td>-0.715957</td>\n",
       "      <td>-0.709046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   open   high    low  close    volume Name  target  year  month  \\\n",
       "0 2013-02-08  15.07  15.12  14.63  14.75   8407500  AAL       1  2013      2   \n",
       "1 2013-02-11  14.89  15.01  14.26  14.46   8882000  AAL       0  2013      2   \n",
       "2 2013-02-12  14.45  14.51  14.10  14.27   8126000  AAL       1  2013      2   \n",
       "3 2013-02-13  14.30  14.94  14.25  14.66  10259500  AAL       1  2013      2   \n",
       "4 2013-02-14  14.94  14.96  13.16  13.99  31879900  AAL       1  2013      2   \n",
       "\n",
       "   day  year_encoded  month_encoded  day_encoded  name_encoded  volume_scaled  \\\n",
       "0    8             0              1            7             1       0.469964   \n",
       "1   11             0              1           10             1       0.524544   \n",
       "2   12             0              1           11             1       0.437583   \n",
       "3   13             0              1           12             1       0.682994   \n",
       "4   14             0              1           13             1       3.169926   \n",
       "\n",
       "   open_scaled  high_scaled  low_scaled  close_scaled  \n",
       "0    -0.697812    -0.699105   -0.700725     -0.701242  \n",
       "1    -0.699661    -0.700225   -0.704559     -0.704220  \n",
       "2    -0.704179    -0.705317   -0.706217     -0.706171  \n",
       "3    -0.705719    -0.700938   -0.704663     -0.702166  \n",
       "4    -0.699147    -0.700735   -0.715957     -0.709046  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520897, 98143)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_date ='2017-05-01'\n",
    "df_training = df.loc[df['date'] <= split_date]\n",
    "df_test = df.loc[df['date'] > split_date]\n",
    "pickle.dump((df_training, df_test), open(\"stock_data.pickle\",'wb'))   \n",
    "len(df_training), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training, df_test = pickle.load(open(\"stock_data.pickle\",'rb'))   \n",
    "y_train = pd.DataFrame(df_training['target'].reset_index())\n",
    "x_train = df_training.drop(['target', 'date', 'Name', 'high', 'close', 'open', 'low','volume', 'year', 'month', 'day'], 1).reset_index()\n",
    "y_test = df_test['target'].reset_index()\n",
    "x_test = pd.DataFrame(df_test.drop(['target', 'date', 'Name', 'high', 'close', 'open', 'low','volume', 'year', 'month', 'day'], 1).reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>year_encoded</th>\n",
       "      <th>month_encoded</th>\n",
       "      <th>day_encoded</th>\n",
       "      <th>name_encoded</th>\n",
       "      <th>volume_scaled</th>\n",
       "      <th>open_scaled</th>\n",
       "      <th>high_scaled</th>\n",
       "      <th>low_scaled</th>\n",
       "      <th>close_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.469964</td>\n",
       "      <td>-0.697812</td>\n",
       "      <td>-0.699105</td>\n",
       "      <td>-0.700725</td>\n",
       "      <td>-0.701242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524544</td>\n",
       "      <td>-0.699661</td>\n",
       "      <td>-0.700225</td>\n",
       "      <td>-0.704559</td>\n",
       "      <td>-0.704220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.437583</td>\n",
       "      <td>-0.704179</td>\n",
       "      <td>-0.705317</td>\n",
       "      <td>-0.706217</td>\n",
       "      <td>-0.706171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.682994</td>\n",
       "      <td>-0.705719</td>\n",
       "      <td>-0.700938</td>\n",
       "      <td>-0.704663</td>\n",
       "      <td>-0.702166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3.169926</td>\n",
       "      <td>-0.699147</td>\n",
       "      <td>-0.700735</td>\n",
       "      <td>-0.715957</td>\n",
       "      <td>-0.709046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  year_encoded  month_encoded  day_encoded  name_encoded  \\\n",
       "0      0             0              1            7             1   \n",
       "1      1             0              1           10             1   \n",
       "2      2             0              1           11             1   \n",
       "3      3             0              1           12             1   \n",
       "4      4             0              1           13             1   \n",
       "\n",
       "   volume_scaled  open_scaled  high_scaled  low_scaled  close_scaled  \n",
       "0       0.469964    -0.697812    -0.699105   -0.700725     -0.701242  \n",
       "1       0.524544    -0.699661    -0.700225   -0.704559     -0.704220  \n",
       "2       0.437583    -0.704179    -0.705317   -0.706217     -0.706171  \n",
       "3       0.682994    -0.705719    -0.700938   -0.704663     -0.702166  \n",
       "4       3.169926    -0.699147    -0.700735   -0.715957     -0.709046  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>year_encoded</th>\n",
       "      <th>month_encoded</th>\n",
       "      <th>day_encoded</th>\n",
       "      <th>name_encoded</th>\n",
       "      <th>volume_scaled</th>\n",
       "      <th>open_scaled</th>\n",
       "      <th>high_scaled</th>\n",
       "      <th>low_scaled</th>\n",
       "      <th>close_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>520897.000000</td>\n",
       "      <td>520897.000000</td>\n",
       "      <td>520897.000000</td>\n",
       "      <td>520897.000000</td>\n",
       "      <td>520897.000000</td>\n",
       "      <td>520897.000000</td>\n",
       "      <td>520897.000000</td>\n",
       "      <td>520897.000000</td>\n",
       "      <td>520897.000000</td>\n",
       "      <td>520897.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>309500.167308</td>\n",
       "      <td>1.746762</td>\n",
       "      <td>5.378344</td>\n",
       "      <td>14.734372</td>\n",
       "      <td>252.969449</td>\n",
       "      <td>0.006122</td>\n",
       "      <td>-0.037528</td>\n",
       "      <td>-0.037406</td>\n",
       "      <td>-0.037650</td>\n",
       "      <td>-0.037509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>178752.783756</td>\n",
       "      <td>1.248651</td>\n",
       "      <td>3.427906</td>\n",
       "      <td>8.722888</td>\n",
       "      <td>145.945788</td>\n",
       "      <td>1.017422</td>\n",
       "      <td>0.918412</td>\n",
       "      <td>0.918690</td>\n",
       "      <td>0.918055</td>\n",
       "      <td>0.918349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.497127</td>\n",
       "      <td>-0.852569</td>\n",
       "      <td>-0.853065</td>\n",
       "      <td>-0.852320</td>\n",
       "      <td>-0.836370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>154548.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>-0.373724</td>\n",
       "      <td>-0.448784</td>\n",
       "      <td>-0.448513</td>\n",
       "      <td>-0.448827</td>\n",
       "      <td>-0.448752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>309841.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>-0.255399</td>\n",
       "      <td>-0.229331</td>\n",
       "      <td>-0.229283</td>\n",
       "      <td>-0.229362</td>\n",
       "      <td>-0.229221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>464245.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.074843</td>\n",
       "      <td>0.074666</td>\n",
       "      <td>0.075175</td>\n",
       "      <td>0.074918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>618844.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>504.000000</td>\n",
       "      <td>70.616963</td>\n",
       "      <td>18.160774</td>\n",
       "      <td>18.400398</td>\n",
       "      <td>18.316203</td>\n",
       "      <td>18.347698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               index   year_encoded  month_encoded    day_encoded  \\\n",
       "count  520897.000000  520897.000000  520897.000000  520897.000000   \n",
       "mean   309500.167308       1.746762       5.378344      14.734372   \n",
       "std    178752.783756       1.248651       3.427906       8.722888   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%    154548.000000       1.000000       2.000000       7.000000   \n",
       "50%    309841.000000       2.000000       5.000000      15.000000   \n",
       "75%    464245.000000       3.000000       8.000000      22.000000   \n",
       "max    618844.000000       4.000000      11.000000      30.000000   \n",
       "\n",
       "        name_encoded  volume_scaled    open_scaled    high_scaled  \\\n",
       "count  520897.000000  520897.000000  520897.000000  520897.000000   \n",
       "mean      252.969449       0.006122      -0.037528      -0.037406   \n",
       "std       145.945788       1.017422       0.918412       0.918690   \n",
       "min         0.000000      -0.497127      -0.852569      -0.853065   \n",
       "25%       126.000000      -0.373724      -0.448784      -0.448513   \n",
       "50%       255.000000      -0.255399      -0.229331      -0.229283   \n",
       "75%       379.000000       0.000929       0.074843       0.074666   \n",
       "max       504.000000      70.616963      18.160774      18.400398   \n",
       "\n",
       "          low_scaled   close_scaled  \n",
       "count  520897.000000  520897.000000  \n",
       "mean       -0.037650      -0.037509  \n",
       "std         0.918055       0.918349  \n",
       "min        -0.852320      -0.836370  \n",
       "25%        -0.448827      -0.448752  \n",
       "50%        -0.229362      -0.229221  \n",
       "75%         0.075175       0.074918  \n",
       "max        18.316203      18.347698  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values[:,1]\n",
    "x_train = x_train.values[:,1:]\n",
    "y_test = y_test.values[:,1]\n",
    "x_test = x_test.values[:,1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    GaussianNB(),\n",
    "    #  RidgeClassifier(tol=1e-2, solver=\"lsqr\"),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    KNeighborsClassifier(3, n_jobs=-1),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1, n_jobs=-1),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    # SVC(kernel=\"linear\", C=0.025, probability=True),\n",
    "    # SVC(gamma=2, C=1, probability=True),\n",
    "    # SVC(),\n",
    "    MLPClassifier(alpha=1),\n",
    "    xgboost.XGBClassifier()\n",
    "    # GaussianProcessClassifier(1.0 * RBF(1.0), n_jobs=-1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "GaussianNB\n",
      "Train/test accuracy:  0.6085905658892257 0.6479728559347075\n",
      "Classification report of Test data\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.97      0.78     63977\n",
      "          1       0.45      0.05      0.09     34166\n",
      "\n",
      "avg / total       0.58      0.65      0.54     98143\n",
      "\n",
      "________________________________________________________________________________\n",
      "QuadraticDiscriminantAnalysis\n",
      "Train/test accuracy:  0.6158108032874061 0.6525274344578829\n",
      "Classification report of Test data\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.93      0.78     63977\n",
      "          1       0.50      0.13      0.20     34166\n",
      "\n",
      "avg / total       0.61      0.65      0.58     98143\n",
      "\n",
      "________________________________________________________________________________\n",
      "LinearDiscriminantAnalysis\n",
      "Train/test accuracy:  0.6187998779029251 0.6573673109646129\n",
      "Classification report of Test data\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.97      0.79     63977\n",
      "          1       0.57      0.07      0.12     34166\n",
      "\n",
      "avg / total       0.63      0.66      0.55     98143\n",
      "\n",
      "________________________________________________________________________________\n",
      "DecisionTreeClassifier\n",
      "Train/test accuracy:  0.6166958151035618 0.6495114272031627\n",
      "Classification report of Test data\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.99      0.79     63977\n",
      "          1       0.38      0.01      0.02     34166\n",
      "\n",
      "avg / total       0.56      0.65      0.52     98143\n",
      "\n",
      "________________________________________________________________________________\n",
      "KNeighborsClassifier\n",
      "Train/test accuracy:  0.779096443250777 0.5884780371498731\n",
      "Classification report of Test data\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.71      0.69     63977\n",
      "          1       0.40      0.37      0.38     34166\n",
      "\n",
      "avg / total       0.58      0.59      0.58     98143\n",
      "\n",
      "________________________________________________________________________________\n",
      "RandomForestClassifier\n",
      "Train/test accuracy:  0.6152809480569095 0.654279979214004\n",
      "Classification report of Test data\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.99      0.79     63977\n",
      "          1       0.57      0.03      0.06     34166\n",
      "\n",
      "avg / total       0.62      0.65      0.53     98143\n",
      "\n",
      "________________________________________________________________________________\n",
      "AdaBoostClassifier\n",
      "Train/test accuracy:  0.6179647799852946 0.6527821648003423\n",
      "Classification report of Test data\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      1.00      0.79     63977\n",
      "          1       0.66      0.01      0.01     34166\n",
      "\n",
      "avg / total       0.66      0.65      0.52     98143\n",
      "\n",
      "________________________________________________________________________________\n",
      "GradientBoostingClassifier\n",
      "Train/test accuracy:  0.6287058669948186 0.653230490203071\n",
      "Classification report of Test data\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.98      0.79     63977\n",
      "          1       0.53      0.04      0.07     34166\n",
      "\n",
      "avg / total       0.61      0.65      0.54     98143\n",
      "\n",
      "________________________________________________________________________________\n",
      "MLPClassifier\n",
      "Train/test accuracy:  0.6113185524201522 0.6522319472606299\n",
      "Classification report of Test data\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      1.00      0.79     63977\n",
      "          1       0.53      0.01      0.02     34166\n",
      "\n",
      "avg / total       0.61      0.65      0.52     98143\n",
      "\n",
      "________________________________________________________________________________\n",
      "XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/test accuracy:  0.6276020019312839 0.6532101117756742\n",
      "Classification report of Test data\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.98      0.79     63977\n",
      "          1       0.53      0.04      0.07     34166\n",
      "\n",
      "avg / total       0.61      0.65      0.54     98143\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "for clf in classifiers:\n",
    "    print('_' * 80)\n",
    "    print(clf.__class__.__name__)\n",
    "    clf.fit(x_train, y_train)\n",
    "    print('Train/test accuracy: ', clf.score(x_train, y_train), clf.score(x_test, y_test))\n",
    "    print('Classification report of Test data')\n",
    "    print(classification_report(y_test, clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model \n",
    "from keras.layers import Input, Dense, Activation, Reshape, merge\n",
    "from keras.layers import Concatenate, Dropout, BatchNormalization\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        Dense(512, activation='relu', input_shape=(x_train.shape[1],)),\n",
    "        Dropout(0.2),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        BatchNormalization(),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 520897 samples, validate on 98143 samples\n",
      "Epoch 1/1\n",
      "520897/520897 [==============================] - 201s 386us/step - loss: 0.6773 - acc: 0.6016 - val_loss: 0.6456 - val_acc: 0.6523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6e08d1cc88>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_year = Input(shape=(1,))\n",
    "output_year = Embedding(5, 2, name='year_embedding')(input_year)\n",
    "output_year = Reshape(target_shape=(2,))(output_year)\n",
    "\n",
    "input_month = Input(shape=(1,))\n",
    "output_month = Embedding(12, 3, name='month_embedding')(input_month)\n",
    "output_month = Reshape(target_shape=(3,))(output_month)\n",
    "\n",
    "input_day = Input(shape=(1,))\n",
    "output_day = Embedding(31, 5, name='day_embedding')(input_day)\n",
    "output_day = Reshape(target_shape=(5,))(output_day)\n",
    "\n",
    "input_name = Input(shape=(1,))\n",
    "output_name = Embedding(505, 10, name='name_embedding')(input_name)\n",
    "output_name = Reshape(target_shape=(10,))(output_name)\n",
    "\n",
    "input_volume = Input(shape=(1,))\n",
    "output_volume = Dense(1)(input_volume)\n",
    "\n",
    "input_open = Input(shape=(1,))\n",
    "output_open = Dense(1)(input_open)\n",
    "\n",
    "input_high = Input(shape=(1,))\n",
    "output_high = Dense(1)(input_high)\n",
    "\n",
    "input_low = Input(shape=(1,))\n",
    "output_low = Dense(1)(input_low)\n",
    "\n",
    "input_close = Input(shape=(1,))\n",
    "output_close = Dense(1)(input_close)\n",
    "\n",
    "input_model = [input_year, input_month, input_day, input_name, input_volume, \n",
    "               input_open, input_high, input_low, input_close]\n",
    "\n",
    "output_embeddings = [output_year, output_month, output_day, output_name, output_volume, \n",
    "               output_open, output_high, output_low, output_close]\n",
    "\n",
    "output_model = Concatenate()(output_embeddings)\n",
    "output_model = Dense(1000, kernel_initializer=\"uniform\")(output_model)\n",
    "output_model = Activation('relu')(output_model)\n",
    "output_model = Dense(500, kernel_initializer=\"uniform\")(output_model)\n",
    "output_model = Activation('relu')(output_model)\n",
    "output_model = Dense(1)(output_model)\n",
    "output_model = Activation('sigmoid')(output_model)\n",
    "\n",
    "entity_model = Model(inputs=input_model, outputs=output_model)\n",
    "\n",
    "entity_model.compile(loss='binary_crossentropy', optimizer='adam',  metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 520897 samples, validate on 98143 samples\n",
      "Epoch 1/10\n",
      "520897/520897 [==============================] - 46s 89us/step - loss: 0.6308 - acc: 0.6459 - val_loss: 0.6812 - val_acc: 0.6432\n",
      "Epoch 2/10\n",
      "520897/520897 [==============================] - 44s 85us/step - loss: 0.5666 - acc: 0.7079 - val_loss: 0.7177 - val_acc: 0.6245\n",
      "Epoch 3/10\n",
      "520897/520897 [==============================] - 44s 85us/step - loss: 0.5260 - acc: 0.7380 - val_loss: 0.7635 - val_acc: 0.6371\n",
      "Epoch 4/10\n",
      "520897/520897 [==============================] - 45s 86us/step - loss: 0.5085 - acc: 0.7487 - val_loss: 0.7457 - val_acc: 0.6335\n",
      "Epoch 5/10\n",
      "520897/520897 [==============================] - 45s 86us/step - loss: 0.4967 - acc: 0.7568 - val_loss: 0.7561 - val_acc: 0.6269\n",
      "Epoch 6/10\n",
      "520897/520897 [==============================] - 45s 86us/step - loss: 0.4875 - acc: 0.7626 - val_loss: 0.7997 - val_acc: 0.6375\n",
      "Epoch 7/10\n",
      "520897/520897 [==============================] - 45s 87us/step - loss: 0.4798 - acc: 0.7671 - val_loss: 0.8429 - val_acc: 0.6275\n",
      "Epoch 8/10\n",
      "520897/520897 [==============================] - 45s 86us/step - loss: 0.4729 - acc: 0.7715 - val_loss: 0.8329 - val_acc: 0.6315\n",
      "Epoch 9/10\n",
      "520897/520897 [==============================] - 44s 85us/step - loss: 0.4670 - acc: 0.7750 - val_loss: 0.8803 - val_acc: 0.6304\n",
      "Epoch 10/10\n",
      "520897/520897 [==============================] - 45s 87us/step - loss: 0.4619 - acc: 0.7783 - val_loss: 0.8539 - val_acc: 0.6305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f68c0745eb8>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_features(X):\n",
    "    X_list = [X[..., [i]] for i in range(9)]\n",
    "    return X_list\n",
    "entity_model.fit(split_features(x_train), y_train,   validation_data=(split_features(x_test), y_test), \n",
    "                 epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raja/.local/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 520897 samples, validate on 98143 samples\n",
      "Epoch 1/10\n",
      "520897/520897 [==============================] - 107s 205us/step - loss: 0.8949 - acc: 0.5858 - val_loss: 0.6475 - val_acc: 0.6520\n",
      "Epoch 2/10\n",
      "520897/520897 [==============================] - 106s 203us/step - loss: 0.6681 - acc: 0.6105 - val_loss: 0.6544 - val_acc: 0.6519\n",
      "Epoch 3/10\n",
      "520897/520897 [==============================] - 104s 200us/step - loss: 0.6673 - acc: 0.6110 - val_loss: 0.6472 - val_acc: 0.6523\n",
      "Epoch 4/10\n",
      "520897/520897 [==============================] - 105s 202us/step - loss: 0.6669 - acc: 0.6112 - val_loss: 0.6472 - val_acc: 0.6523\n",
      "Epoch 5/10\n",
      "520897/520897 [==============================] - 105s 201us/step - loss: 0.6662 - acc: 0.6109 - val_loss: 0.6538 - val_acc: 0.6394\n",
      "Epoch 6/10\n",
      "520897/520897 [==============================] - 105s 201us/step - loss: 0.6659 - acc: 0.6110 - val_loss: 0.6443 - val_acc: 0.6521\n",
      "Epoch 7/10\n",
      "520897/520897 [==============================] - 105s 202us/step - loss: 0.6657 - acc: 0.6110 - val_loss: 0.6459 - val_acc: 0.6520\n",
      "Epoch 8/10\n",
      "520897/520897 [==============================] - 105s 202us/step - loss: 0.6657 - acc: 0.6110 - val_loss: 0.6478 - val_acc: 0.6520\n",
      "Epoch 9/10\n",
      "520897/520897 [==============================] - 105s 201us/step - loss: 0.6656 - acc: 0.6110 - val_loss: 0.6466 - val_acc: 0.6522\n",
      "Epoch 10/10\n",
      "520897/520897 [==============================] - 105s 202us/step - loss: 0.6655 - acc: 0.6110 - val_loss: 0.6581 - val_acc: 0.6417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6dddc051d0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "inputs = Input(shape=(x_train.shape[1],))\n",
    "\n",
    "# ATTENTION PART STARTS HERE\n",
    "attention_probs = Dense(x_train.shape[1], activation='softmax', name='attention_vec')(inputs)\n",
    "attention_mul = Concatenate()([inputs, attention_probs])\n",
    "# ATTENTION PART FINISHES HERE\n",
    "\n",
    "attention_mul = Dense(128)(attention_mul)\n",
    "attention_mul = Dense(128)(attention_mul)\n",
    "output = Dense(1, activation='sigmoid')(attention_mul)\n",
    "attention_model = Model(input=[inputs], output=output)\n",
    "attention_model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['acc'])\n",
    "\n",
    "attention_model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
