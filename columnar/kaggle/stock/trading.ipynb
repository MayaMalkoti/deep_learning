{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-08</td>\n",
       "      <td>15.07</td>\n",
       "      <td>15.12</td>\n",
       "      <td>14.63</td>\n",
       "      <td>14.75</td>\n",
       "      <td>8407500</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-02-11</td>\n",
       "      <td>14.89</td>\n",
       "      <td>15.01</td>\n",
       "      <td>14.26</td>\n",
       "      <td>14.46</td>\n",
       "      <td>8882000</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-02-12</td>\n",
       "      <td>14.45</td>\n",
       "      <td>14.51</td>\n",
       "      <td>14.10</td>\n",
       "      <td>14.27</td>\n",
       "      <td>8126000</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-02-13</td>\n",
       "      <td>14.30</td>\n",
       "      <td>14.94</td>\n",
       "      <td>14.25</td>\n",
       "      <td>14.66</td>\n",
       "      <td>10259500</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-02-14</td>\n",
       "      <td>14.94</td>\n",
       "      <td>14.96</td>\n",
       "      <td>13.16</td>\n",
       "      <td>13.99</td>\n",
       "      <td>31879900</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   open   high    low  close    volume Name\n",
       "0  2013-02-08  15.07  15.12  14.63  14.75   8407500  AAL\n",
       "1  2013-02-11  14.89  15.01  14.26  14.46   8882000  AAL\n",
       "2  2013-02-12  14.45  14.51  14.10  14.27   8126000  AAL\n",
       "3  2013-02-13  14.30  14.94  14.25  14.66  10259500  AAL\n",
       "4  2013-02-14  14.94  14.96  13.16  13.99  31879900  AAL"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('all_stocks_5yr.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = 0\n",
    "for idx, row in df.iterrows():\n",
    "    today_close = df.iloc[idx]['close']\n",
    "    try:\n",
    "        tomorrow_high = df.iloc[idx+1]['high'] \n",
    "    except IndexError:\n",
    "        break\n",
    "    if (0.99*tomorrow_high) <= today_close:\n",
    "        df.iat[idx, 7] = 0\n",
    "    else:\n",
    "        df.iat[idx, 7] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520897, 98143)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_date ='2017-05-01'\n",
    "df_training = df.loc[df['date'] <= split_date]\n",
    "df_test = df.loc[df['date'] > split_date]\n",
    "len(df_training), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame(df_training['target'].reset_index().fillna(0))\n",
    "x_train = df_training.drop(['target', 'date', 'Name'], 1).reset_index().fillna(0)\n",
    "y_test = df_test['target'].reset_index().fillna(0)\n",
    "x_test = pd.DataFrame(df_test.drop(['target', 'date', 'Name'], 1).reset_index().fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values[:,1]\n",
    "x_train = x_train.values[:,1:]\n",
    "y_test = y_test.values[:,1]\n",
    "x_test = x_test.values[:,1:]\n",
    "pickle.dump((x_train, y_train, x_test, y_test), open(\"stock_data.pickle\",'wb'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    GaussianNB(),\n",
    "    #  RidgeClassifier(tol=1e-2, solver=\"lsqr\"),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    KNeighborsClassifier(3, n_jobs=-1),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1, n_jobs=-1),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    # SVC(kernel=\"linear\", C=0.025, probability=True),\n",
    "    # SVC(gamma=2, C=1, probability=True),\n",
    "    # SVC(),\n",
    "    MLPClassifier(alpha=1),\n",
    "    # GaussianProcessClassifier(1.0 * RBF(1.0), n_jobs=-1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "GaussianNB\n",
      "Train/test accuracy:  0.609108902527755 0.6490427233730373\n",
      "Classification report of Test data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.97      0.78     63974\n",
      "           1       0.46      0.04      0.08     34169\n",
      "\n",
      "   micro avg       0.65      0.65      0.65     98143\n",
      "   macro avg       0.56      0.51      0.43     98143\n",
      "weighted avg       0.59      0.65      0.54     98143\n",
      "\n",
      "________________________________________________________________________________\n",
      "QuadraticDiscriminantAnalysis\n",
      "Train/test accuracy:  0.6153634979660086 0.6520281629866623\n",
      "Classification report of Test data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.94      0.78     63974\n",
      "           1       0.50      0.12      0.20     34169\n",
      "\n",
      "   micro avg       0.65      0.65      0.65     98143\n",
      "   macro avg       0.58      0.53      0.49     98143\n",
      "weighted avg       0.61      0.65      0.58     98143\n",
      "\n",
      "________________________________________________________________________________\n",
      "LinearDiscriminantAnalysis\n",
      "Train/test accuracy:  0.6187442047084164 0.6570718237673598\n",
      "Classification report of Test data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.97      0.79     63974\n",
      "           1       0.57      0.06      0.11     34169\n",
      "\n",
      "   micro avg       0.66      0.66      0.66     98143\n",
      "   macro avg       0.61      0.52      0.45     98143\n",
      "weighted avg       0.63      0.66      0.55     98143\n",
      "\n",
      "________________________________________________________________________________\n",
      "DecisionTreeClassifier\n",
      "Train/test accuracy:  0.6144228129553443 0.648818560671673\n",
      "Classification report of Test data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.96      0.78     63974\n",
      "           1       0.47      0.07      0.13     34169\n",
      "\n",
      "   micro avg       0.65      0.65      0.65     98143\n",
      "   macro avg       0.57      0.51      0.45     98143\n",
      "weighted avg       0.59      0.65      0.55     98143\n",
      "\n",
      "________________________________________________________________________________\n",
      "KNeighborsClassifier\n",
      "Train/test accuracy:  0.7643795222472005 0.5583179646026716\n",
      "Classification report of Test data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.67      0.67     63974\n",
      "           1       0.36      0.34      0.35     34169\n",
      "\n",
      "   micro avg       0.56      0.56      0.56     98143\n",
      "   macro avg       0.51      0.51      0.51     98143\n",
      "weighted avg       0.55      0.56      0.56     98143\n",
      "\n",
      "________________________________________________________________________________\n",
      "RandomForestClassifier\n",
      "Train/test accuracy:  0.6146051906614936 0.6516205944387272\n",
      "Classification report of Test data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.98      0.79     63974\n",
      "           1       0.50      0.04      0.07     34169\n",
      "\n",
      "   micro avg       0.65      0.65      0.65     98143\n",
      "   macro avg       0.58      0.51      0.43     98143\n",
      "weighted avg       0.60      0.65      0.54     98143\n",
      "\n",
      "________________________________________________________________________________\n",
      "AdaBoostClassifier\n",
      "Train/test accuracy:  0.6133899792089414 0.6524255423208991\n",
      "Classification report of Test data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.99      0.79     63974\n",
      "           1       0.52      0.03      0.05     34169\n",
      "\n",
      "   micro avg       0.65      0.65      0.65     98143\n",
      "   macro avg       0.59      0.51      0.42     98143\n",
      "weighted avg       0.61      0.65      0.53     98143\n",
      "\n",
      "________________________________________________________________________________\n",
      "GradientBoostingClassifier\n",
      "Train/test accuracy:  0.6164827211521664 0.6532916254852613\n",
      "Classification report of Test data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.98      0.79     63974\n",
      "           1       0.53      0.04      0.08     34169\n",
      "\n",
      "   micro avg       0.65      0.65      0.65     98143\n",
      "   macro avg       0.59      0.51      0.43     98143\n",
      "weighted avg       0.61      0.65      0.54     98143\n",
      "\n",
      "________________________________________________________________________________\n",
      "MLPClassifier\n",
      "Train/test accuracy:  0.6111380944793309 0.6518447571400915\n",
      "Classification report of Test data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79     63974\n",
      "           1       0.00      0.00      0.00     34169\n",
      "\n",
      "   micro avg       0.65      0.65      0.65     98143\n",
      "   macro avg       0.33      0.50      0.39     98143\n",
      "weighted avg       0.42      0.65      0.51     98143\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for clf in classifiers:\n",
    "    print('_' * 80)\n",
    "    print(clf.__class__.__name__)\n",
    "    clf.fit(x_train, y_train)\n",
    "    print('Train/test accuracy: ', clf.score(x_train, y_train), clf.score(x_test, y_test))\n",
    "    print('Classification report of Test data')\n",
    "    print(classification_report(y_test, clf.predict(x_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
